{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline_sentiment_confidence</th>\n",
       "      <th>negativereason</th>\n",
       "      <th>negativereason_confidence</th>\n",
       "      <th>airline</th>\n",
       "      <th>airline_sentiment_gold</th>\n",
       "      <th>name</th>\n",
       "      <th>negativereason_gold</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_coord</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>user_timezone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>570306133677760513</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cairdin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:35:52 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>570301130888122368</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.3486</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:59 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>570301083672813571</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.6837</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yvonnalynn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:48 -0800</td>\n",
       "      <td>Lets Play</td>\n",
       "      <td>Central Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>570301031407624196</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Bad Flight</td>\n",
       "      <td>0.7033</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:36 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>570300817074462722</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Can't Tell</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:14:45 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id airline_sentiment  airline_sentiment_confidence  \\\n",
       "0  570306133677760513           neutral                        1.0000   \n",
       "1  570301130888122368          positive                        0.3486   \n",
       "2  570301083672813571           neutral                        0.6837   \n",
       "3  570301031407624196          negative                        1.0000   \n",
       "4  570300817074462722          negative                        1.0000   \n",
       "\n",
       "  negativereason  negativereason_confidence         airline  \\\n",
       "0            NaN                        NaN  Virgin America   \n",
       "1            NaN                     0.0000  Virgin America   \n",
       "2            NaN                        NaN  Virgin America   \n",
       "3     Bad Flight                     0.7033  Virgin America   \n",
       "4     Can't Tell                     1.0000  Virgin America   \n",
       "\n",
       "  airline_sentiment_gold        name negativereason_gold  retweet_count  \\\n",
       "0                    NaN     cairdin                 NaN              0   \n",
       "1                    NaN    jnardino                 NaN              0   \n",
       "2                    NaN  yvonnalynn                 NaN              0   \n",
       "3                    NaN    jnardino                 NaN              0   \n",
       "4                    NaN    jnardino                 NaN              0   \n",
       "\n",
       "                                                text tweet_coord  \\\n",
       "0                @VirginAmerica What @dhepburn said.         NaN   \n",
       "1  @VirginAmerica plus you've added commercials t...         NaN   \n",
       "2  @VirginAmerica I didn't today... Must mean I n...         NaN   \n",
       "3  @VirginAmerica it's really aggressive to blast...         NaN   \n",
       "4  @VirginAmerica and it's a really big bad thing...         NaN   \n",
       "\n",
       "               tweet_created tweet_location               user_timezone  \n",
       "0  2015-02-24 11:35:52 -0800            NaN  Eastern Time (US & Canada)  \n",
       "1  2015-02-24 11:15:59 -0800            NaN  Pacific Time (US & Canada)  \n",
       "2  2015-02-24 11:15:48 -0800      Lets Play  Central Time (US & Canada)  \n",
       "3  2015-02-24 11:15:36 -0800            NaN  Pacific Time (US & Canada)  \n",
       "4  2015-02-24 11:14:45 -0800            NaN  Pacific Time (US & Canada)  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[['airline_sentiment', 'text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>neutral</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>neutral</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>negative</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>negative</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  airline_sentiment                                               text\n",
       "0           neutral                @VirginAmerica What @dhepburn said.\n",
       "1          positive  @VirginAmerica plus you've added commercials t...\n",
       "2           neutral  @VirginAmerica I didn't today... Must mean I n...\n",
       "3          negative  @VirginAmerica it's really aggressive to blast...\n",
       "4          negative  @VirginAmerica and it's a really big bad thing..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['neutral', 'positive', 'negative'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.airline_sentiment.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "negative    9178\n",
       "neutral     3099\n",
       "positive    2363\n",
       "Name: airline_sentiment, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.airline_sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_positive = data[data.airline_sentiment == 'positive']\n",
    "data_negative = data[data.airline_sentiment == 'negative']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_negative = data_negative.iloc[:len(data_positive)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2363"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2363"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([data_negative, data_positive])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2251</td>\n",
       "      <td>negative</td>\n",
       "      <td>@united 4595. We are now going back to the gat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4041</td>\n",
       "      <td>positive</td>\n",
       "      <td>@United Bringing your \"A\" game with premium ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10428</td>\n",
       "      <td>positive</td>\n",
       "      <td>@USAirways thank you!!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1172</td>\n",
       "      <td>negative</td>\n",
       "      <td>@united and those three people were awesome wo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11839</td>\n",
       "      <td>positive</td>\n",
       "      <td>@USAirways will do. Hoping for a voucher for a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1343</td>\n",
       "      <td>positive</td>\n",
       "      <td>@united I am impressed with your super-fast re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2018</td>\n",
       "      <td>positive</td>\n",
       "      <td>@united met with agent. All taken care of. Thx...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>366</td>\n",
       "      <td>negative</td>\n",
       "      <td>@VirginAmerica I have 2d and 3d embossed badge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>127</td>\n",
       "      <td>positive</td>\n",
       "      <td>@VirginAmerica completely awesome experience l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1418</td>\n",
       "      <td>negative</td>\n",
       "      <td>@united does asap mean two hours worth of dela...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4726 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      airline_sentiment                                               text\n",
       "2251           negative  @united 4595. We are now going back to the gat...\n",
       "4041           positive  @United Bringing your \"A\" game with premium ca...\n",
       "10428          positive                            @USAirways thank you!!!\n",
       "1172           negative  @united and those three people were awesome wo...\n",
       "11839          positive  @USAirways will do. Hoping for a voucher for a...\n",
       "...                 ...                                                ...\n",
       "1343           positive  @united I am impressed with your super-fast re...\n",
       "2018           positive  @united met with agent. All taken care of. Thx...\n",
       "366            negative  @VirginAmerica I have 2d and 3d embossed badge...\n",
       "127            positive  @VirginAmerica completely awesome experience l...\n",
       "1418           negative  @united does asap mean two hours worth of dela...\n",
       "\n",
       "[4726 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sample(len(data))                                   #乱序"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['review'] = (data.airline_sentiment == 'positive').astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "del data['airline_sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>@VirginAmerica seriously would pay $30 a fligh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>@VirginAmerica SFO-PDX schedule is still MIA.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>@VirginAmerica  I flew from NYC to SFO last we...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14623</td>\n",
       "      <td>@AmericanAir Love the new planes for the JFK-L...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14625</td>\n",
       "      <td>@AmericanAir Flight 236 was great. Fantastic c...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14628</td>\n",
       "      <td>Thank you. “@AmericanAir: @jlhalldc Customer R...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14630</td>\n",
       "      <td>@AmericanAir Thanks! He is.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14635</td>\n",
       "      <td>@AmericanAir thank you we got on a different f...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4726 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  review\n",
       "3      @VirginAmerica it's really aggressive to blast...       0\n",
       "4      @VirginAmerica and it's a really big bad thing...       0\n",
       "5      @VirginAmerica seriously would pay $30 a fligh...       0\n",
       "15         @VirginAmerica SFO-PDX schedule is still MIA.       0\n",
       "17     @VirginAmerica  I flew from NYC to SFO last we...       0\n",
       "...                                                  ...     ...\n",
       "14623  @AmericanAir Love the new planes for the JFK-L...       1\n",
       "14625  @AmericanAir Flight 236 was great. Fantastic c...       1\n",
       "14628  Thank you. “@AmericanAir: @jlhalldc Customer R...       1\n",
       "14630                        @AmericanAir Thanks! He is.       1\n",
       "14635  @AmericanAir thank you we got on a different f...       1\n",
       "\n",
       "[4726 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re                                                         #使用正则去除特殊字符"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "token = re.compile('[A-Za-z]+|[!?,.()$]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reg_text(text):\n",
    "    new_text = token.findall(text)\n",
    "    new_text = [word.lower() for word in new_text]\n",
    "    return new_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['text'] = data.text.apply(reg_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>[virginamerica, it, s, really, aggressive, to,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>[virginamerica, and, it, s, a, really, big, ba...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>[virginamerica, seriously, would, pay, $, a, f...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>[virginamerica, sfo, pdx, schedule, is, still,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>[virginamerica, i, flew, from, nyc, to, sfo, l...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14623</td>\n",
       "      <td>[americanair, love, the, new, planes, for, the...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14625</td>\n",
       "      <td>[americanair, flight, was, great, ., fantastic...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14628</td>\n",
       "      <td>[thank, you, ., americanair, jlhalldc, custome...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14630</td>\n",
       "      <td>[americanair, thanks, !, he, is, .]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14635</td>\n",
       "      <td>[americanair, thank, you, we, got, on, a, diff...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4726 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  review\n",
       "3      [virginamerica, it, s, really, aggressive, to,...       0\n",
       "4      [virginamerica, and, it, s, a, really, big, ba...       0\n",
       "5      [virginamerica, seriously, would, pay, $, a, f...       0\n",
       "15     [virginamerica, sfo, pdx, schedule, is, still,...       0\n",
       "17     [virginamerica, i, flew, from, nyc, to, sfo, l...       0\n",
       "...                                                  ...     ...\n",
       "14623  [americanair, love, the, new, planes, for, the...       1\n",
       "14625  [americanair, flight, was, great, ., fantastic...       1\n",
       "14628  [thank, you, ., americanair, jlhalldc, custome...       1\n",
       "14630                [americanair, thanks, !, he, is, .]       1\n",
       "14635  [americanair, thank, you, we, got, on, a, diff...       1\n",
       "\n",
       "[4726 rows x 2 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_set = set()\n",
    "for text in data.text:\n",
    "    for word in text:\n",
    "        word_set.add(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7101"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_word = len(word_set)                       #set数据结构会去除所有重复值\n",
    "max_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list = list(word_set)          #转换为list列表数据结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5251"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_list.index('you')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = dict((word, word_list.index(word) + 1) for word in word_list)           #将list转化为字典"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'inpolite': 1,\n",
       " 'swapping': 2,\n",
       " 'el': 3,\n",
       " 'remembering': 4,\n",
       " 'jackson': 5,\n",
       " 'hats': 6,\n",
       " 'oaflfr': 7,\n",
       " 'malfunction': 8,\n",
       " 'ceases': 9,\n",
       " 'hey': 10,\n",
       " 'east': 11,\n",
       " 'raleigh': 12,\n",
       " 'xbo': 13,\n",
       " 'sons': 14,\n",
       " 'abassinet': 15,\n",
       " 'routing': 16,\n",
       " 'exact': 17,\n",
       " 'zf': 18,\n",
       " 'departs': 19,\n",
       " 'ciscojimfrench': 20,\n",
       " 'beautiful': 21,\n",
       " 'monitoring': 22,\n",
       " 'randomly': 23,\n",
       " 'mommy': 24,\n",
       " 'hqoks': 25,\n",
       " 'yosjhzmc': 26,\n",
       " 'luxclark': 27,\n",
       " 'nader': 28,\n",
       " 'fresh': 29,\n",
       " 'hrs': 30,\n",
       " 'xelbon': 31,\n",
       " 'substandard': 32,\n",
       " 'sheila': 33,\n",
       " 'contacting': 34,\n",
       " 'squished': 35,\n",
       " 'have': 36,\n",
       " 'did': 37,\n",
       " 'need': 38,\n",
       " 'throw': 39,\n",
       " 'npxb': 40,\n",
       " 'sked': 41,\n",
       " 'tonite': 42,\n",
       " 'bostonlogan': 43,\n",
       " 'leopolds': 44,\n",
       " 'prize': 45,\n",
       " 'sadie': 46,\n",
       " 'expense': 47,\n",
       " 'more': 48,\n",
       " 'fulfill': 49,\n",
       " 'rad': 50,\n",
       " 'celebrating': 51,\n",
       " 'tho': 52,\n",
       " 'registration': 53,\n",
       " 'joanna': 54,\n",
       " 'dealing': 55,\n",
       " 'feels': 56,\n",
       " 'transpacific': 57,\n",
       " 'inspiring': 58,\n",
       " 'suck': 59,\n",
       " 'helpfulness': 60,\n",
       " 'mammoth': 61,\n",
       " 'cake': 62,\n",
       " 'victoria': 63,\n",
       " 'card': 64,\n",
       " 'gesture': 65,\n",
       " 'wastedtime': 66,\n",
       " 'ivgpzsjtkw': 67,\n",
       " 'sunrise': 68,\n",
       " 'over': 69,\n",
       " 'kdzqczlpyr': 70,\n",
       " 'horrid': 71,\n",
       " 'here': 72,\n",
       " 'nwk': 73,\n",
       " 'intro': 74,\n",
       " 'rsw': 75,\n",
       " 'creates': 76,\n",
       " 'floor': 77,\n",
       " 'unscheduled': 78,\n",
       " 'tailwind': 79,\n",
       " 'multipledooropeningandclosing': 80,\n",
       " 'katie': 81,\n",
       " 'mistake': 82,\n",
       " 'anything': 83,\n",
       " 'julian': 84,\n",
       " 'louis': 85,\n",
       " 'vr': 86,\n",
       " 'overwhelmed': 87,\n",
       " 'laptop': 88,\n",
       " 'lou': 89,\n",
       " 'ons': 90,\n",
       " 'used': 91,\n",
       " 'sunset': 92,\n",
       " 'requested': 93,\n",
       " 'access': 94,\n",
       " 'catsanddogslivingtogether': 95,\n",
       " 'shawn': 96,\n",
       " 'keep': 97,\n",
       " 'tongue': 98,\n",
       " 'persisting': 99,\n",
       " 'veqhghy': 100,\n",
       " 'earphone': 101,\n",
       " 'businesstravel': 102,\n",
       " 'jq': 103,\n",
       " 'breathing': 104,\n",
       " 'portland': 105,\n",
       " 'gopatriots': 106,\n",
       " 'building': 107,\n",
       " 'onelove': 108,\n",
       " 'samoore': 109,\n",
       " 'qyezhjgsb': 110,\n",
       " 'doing': 111,\n",
       " 'available': 112,\n",
       " 'thrown': 113,\n",
       " 'interiors': 114,\n",
       " 'unitedairlinessucks': 115,\n",
       " 'welldone': 116,\n",
       " 'takemeback': 117,\n",
       " 'caned': 118,\n",
       " 'remote': 119,\n",
       " 'worrisome': 120,\n",
       " 'going': 121,\n",
       " 'thailand': 122,\n",
       " 'steps': 123,\n",
       " 'resend': 124,\n",
       " 'neglect': 125,\n",
       " 'diff': 126,\n",
       " 'screens': 127,\n",
       " 'keepitmovin': 128,\n",
       " 'lower': 129,\n",
       " 'generally': 130,\n",
       " 'repeatedly': 131,\n",
       " 'twelve': 132,\n",
       " 'connected': 133,\n",
       " 'street': 134,\n",
       " 'thnx': 135,\n",
       " 'amounts': 136,\n",
       " 'ahlxhhkiyn': 137,\n",
       " 'aaaand': 138,\n",
       " 'elevategold': 139,\n",
       " 'pm': 140,\n",
       " 'fidifamilies': 141,\n",
       " 'wishmyflightwaslonger': 142,\n",
       " 'holder': 143,\n",
       " 'justdoit': 144,\n",
       " 'intended': 145,\n",
       " 'svc': 146,\n",
       " 'wife': 147,\n",
       " 'jam': 148,\n",
       " 'noservice': 149,\n",
       " 'reported': 150,\n",
       " 'letting': 151,\n",
       " 'happycamper': 152,\n",
       " 'rotten': 153,\n",
       " 'gqdt': 154,\n",
       " 'wrote': 155,\n",
       " 'them': 156,\n",
       " 'rd': 157,\n",
       " 'lostsuitcase': 158,\n",
       " 'thru': 159,\n",
       " 'sides': 160,\n",
       " 'boldflavors': 161,\n",
       " 'nruovts': 162,\n",
       " 'amazed': 163,\n",
       " 'preventative': 164,\n",
       " 'globe': 165,\n",
       " 'via': 166,\n",
       " 'strip': 167,\n",
       " 'john': 168,\n",
       " 'sotelo': 169,\n",
       " 'network': 170,\n",
       " 'buzj': 171,\n",
       " 'didnt': 172,\n",
       " 'meal': 173,\n",
       " 'tuxfqf': 174,\n",
       " 'request': 175,\n",
       " 'lindaswc': 176,\n",
       " 'spare': 177,\n",
       " 'beanie': 178,\n",
       " 'entire': 179,\n",
       " 'sleeping': 180,\n",
       " 'tammy': 181,\n",
       " 'commission': 182,\n",
       " 'arrival': 183,\n",
       " 'huston': 184,\n",
       " 'bluetiful': 185,\n",
       " 'charges': 186,\n",
       " 'three': 187,\n",
       " 'goal': 188,\n",
       " 'palm': 189,\n",
       " 'hanging': 190,\n",
       " 'fan': 191,\n",
       " 'performance': 192,\n",
       " 'aufm': 193,\n",
       " 'nightmare': 194,\n",
       " 'costing': 195,\n",
       " 'exclusively': 196,\n",
       " 'elizabeth': 197,\n",
       " 'doesnt': 198,\n",
       " 'guiltypleasures': 199,\n",
       " 'kdmq': 200,\n",
       " 'laguardia': 201,\n",
       " 'non': 202,\n",
       " 'portlandjetport': 203,\n",
       " 'commute': 204,\n",
       " 'ntrustopen': 205,\n",
       " 'trying': 206,\n",
       " 'luvsw': 207,\n",
       " 'shameful': 208,\n",
       " 'voucher': 209,\n",
       " 'carrying': 210,\n",
       " 'redeem': 211,\n",
       " 'carriers': 212,\n",
       " 'face': 213,\n",
       " 'explanation': 214,\n",
       " 'inconveniences': 215,\n",
       " 'friends': 216,\n",
       " 'according': 217,\n",
       " 'chat': 218,\n",
       " 'tampa': 219,\n",
       " 'cali': 220,\n",
       " 'millions': 221,\n",
       " 'disneyland': 222,\n",
       " 'speed': 223,\n",
       " 'vouchers': 224,\n",
       " 'utah': 225,\n",
       " 'flustered': 226,\n",
       " 'continentalairlines': 227,\n",
       " 'compensating': 228,\n",
       " 'members': 229,\n",
       " 'msy': 230,\n",
       " 'separated': 231,\n",
       " 'closed': 232,\n",
       " 'kchnr': 233,\n",
       " 'flythefriendlyskies': 234,\n",
       " 'undergoing': 235,\n",
       " 'received': 236,\n",
       " 'dishonoring': 237,\n",
       " 'havana': 238,\n",
       " 'gok': 239,\n",
       " 'anotherdisappointment': 240,\n",
       " 'either': 241,\n",
       " 'stated': 242,\n",
       " 'needtobehonest': 243,\n",
       " 'magic': 244,\n",
       " 'stamp': 245,\n",
       " 'feedback': 246,\n",
       " 'apathy': 247,\n",
       " 'insulted': 248,\n",
       " 'love': 249,\n",
       " 'grounded': 250,\n",
       " 'mqxc': 251,\n",
       " 'logistics': 252,\n",
       " 'phxskyharbor': 253,\n",
       " 'expeditious': 254,\n",
       " 'ans': 255,\n",
       " 'trained': 256,\n",
       " 'god': 257,\n",
       " 'charter': 258,\n",
       " 'remedy': 259,\n",
       " 'freecomedyshow': 260,\n",
       " 'veggies': 261,\n",
       " 'allergy': 262,\n",
       " 'ifc': 263,\n",
       " 'reeks': 264,\n",
       " 'sadly': 265,\n",
       " 'gang': 266,\n",
       " 'wallet': 267,\n",
       " 'uncomfortable': 268,\n",
       " 'terribleservice': 269,\n",
       " 'guitar': 270,\n",
       " 'dependable': 271,\n",
       " 'level': 272,\n",
       " 'consolation': 273,\n",
       " 'economic': 274,\n",
       " 'ios': 275,\n",
       " 'faces': 276,\n",
       " 'works': 277,\n",
       " 'failures': 278,\n",
       " 'batting': 279,\n",
       " 'nas': 280,\n",
       " 'admirals': 281,\n",
       " 'burlington': 282,\n",
       " 'prefer': 283,\n",
       " 'friday': 284,\n",
       " 'counter': 285,\n",
       " 'masters': 286,\n",
       " 'fwzclbvug': 287,\n",
       " 'password': 288,\n",
       " 'dude': 289,\n",
       " 'hdn': 290,\n",
       " 'dwell': 291,\n",
       " 'attendant': 292,\n",
       " 'quote': 293,\n",
       " 'driven': 294,\n",
       " 'map': 295,\n",
       " 'find': 296,\n",
       " 'grr': 297,\n",
       " 'above': 298,\n",
       " 'engagement': 299,\n",
       " 'alerts': 300,\n",
       " 'flyerfriendly': 301,\n",
       " 'eliza': 302,\n",
       " 'insurance': 303,\n",
       " 'replacing': 304,\n",
       " 'steal': 305,\n",
       " 'barrel': 306,\n",
       " 'extravaganza': 307,\n",
       " 'udub': 308,\n",
       " 'jbdkxd': 309,\n",
       " 'spectacular': 310,\n",
       " 'fails': 311,\n",
       " 'crappy': 312,\n",
       " 'wjgtxzt': 313,\n",
       " 'jetway': 314,\n",
       " 'kmquly': 315,\n",
       " 'uygew': 316,\n",
       " 'lining': 317,\n",
       " 'tmobile': 318,\n",
       " 'concerns': 319,\n",
       " 'cement': 320,\n",
       " 'dal': 321,\n",
       " 'airlines': 322,\n",
       " 'sooo': 323,\n",
       " 'norm': 324,\n",
       " 'address': 325,\n",
       " 'cudtomers': 326,\n",
       " 'acosta': 327,\n",
       " 'newflight': 328,\n",
       " 'px': 329,\n",
       " 'impacts': 330,\n",
       " 'field': 331,\n",
       " 'spirits': 332,\n",
       " 'seriously': 333,\n",
       " 'packing': 334,\n",
       " 'obvious': 335,\n",
       " 'rachelle': 336,\n",
       " 'ladygaga': 337,\n",
       " 'acceptable': 338,\n",
       " 'makingthingseasy': 339,\n",
       " 'kinda': 340,\n",
       " 'roadwarrior': 341,\n",
       " 'mech': 342,\n",
       " 'shuttle': 343,\n",
       " 'text': 344,\n",
       " 'lovejetblue': 345,\n",
       " 'saw': 346,\n",
       " 'guidelines': 347,\n",
       " 'proficient': 348,\n",
       " 'tel': 349,\n",
       " 'andrews': 350,\n",
       " 'dnx': 351,\n",
       " 'msnbc': 352,\n",
       " 'massive': 353,\n",
       " 'iyhi': 354,\n",
       " 'comped': 355,\n",
       " 'satisfactory': 356,\n",
       " 'cover': 357,\n",
       " 'iphone': 358,\n",
       " 'nfl': 359,\n",
       " 'pittsburgh': 360,\n",
       " 'wjere': 361,\n",
       " 'expects': 362,\n",
       " 'greed': 363,\n",
       " 'cantlogoutofunitedwifi': 364,\n",
       " 'oumc': 365,\n",
       " 'constructive': 366,\n",
       " 'tonysimsmma': 367,\n",
       " 'error': 368,\n",
       " 'mere': 369,\n",
       " 'overcharging': 370,\n",
       " 'contest': 371,\n",
       " 'surgery': 372,\n",
       " 'impolite': 373,\n",
       " 'dean': 374,\n",
       " 'plate': 375,\n",
       " 'push': 376,\n",
       " 'wonked': 377,\n",
       " 'internship': 378,\n",
       " 'cxcld': 379,\n",
       " 'gotten': 380,\n",
       " 'continually': 381,\n",
       " 'zz': 382,\n",
       " 'losing': 383,\n",
       " 'aviation': 384,\n",
       " 'delivery': 385,\n",
       " 'smoooothest': 386,\n",
       " 'vincenzolandino': 387,\n",
       " 'uncle': 388,\n",
       " 'sell': 389,\n",
       " 'shampoo': 390,\n",
       " 'range': 391,\n",
       " 'clients': 392,\n",
       " 'pqds': 393,\n",
       " 'scheme': 394,\n",
       " 'ch': 395,\n",
       " 'fashion': 396,\n",
       " 'sliced': 397,\n",
       " 'hopefully': 398,\n",
       " 'phone': 399,\n",
       " 'misses': 400,\n",
       " 'nqh': 401,\n",
       " 'design': 402,\n",
       " 'switched': 403,\n",
       " 'california': 404,\n",
       " 'advantage': 405,\n",
       " 'thats': 406,\n",
       " 'customers': 407,\n",
       " 'integrating': 408,\n",
       " 'suite': 409,\n",
       " 'tactic': 410,\n",
       " 'stopped': 411,\n",
       " 'yummy': 412,\n",
       " 'ur': 413,\n",
       " 'jx': 414,\n",
       " 'owner': 415,\n",
       " 'miscalculation': 416,\n",
       " 'against': 417,\n",
       " 'screaming': 418,\n",
       " 'snowstorm': 419,\n",
       " 'dam': 420,\n",
       " 'plan': 421,\n",
       " 'pricey': 422,\n",
       " 'abcnetwork': 423,\n",
       " 'flies': 424,\n",
       " 'nonupgrade': 425,\n",
       " 'noted': 426,\n",
       " 'cancun': 427,\n",
       " 'threw': 428,\n",
       " 'regards': 429,\n",
       " 'cc': 430,\n",
       " 'corevalues': 431,\n",
       " 'miraculously': 432,\n",
       " 'lifeneedsfrosting': 433,\n",
       " 'subsequently': 434,\n",
       " 'greetings': 435,\n",
       " 'empathy': 436,\n",
       " 'apostrophefail': 437,\n",
       " 'language': 438,\n",
       " 'bounce': 439,\n",
       " 'swaculture': 440,\n",
       " 'enjoyable': 441,\n",
       " 'ugh': 442,\n",
       " 'cyd': 443,\n",
       " 'ratings': 444,\n",
       " 'shambles': 445,\n",
       " 'flightled': 446,\n",
       " 'duty': 447,\n",
       " 'qantas': 448,\n",
       " 'demoted': 449,\n",
       " 'umosaicmecrazy': 450,\n",
       " 'rockinwellness': 451,\n",
       " 'fernheinig': 452,\n",
       " 'umhbh': 453,\n",
       " 'wendi': 454,\n",
       " 'wiped': 455,\n",
       " 'weird': 456,\n",
       " 'nola': 457,\n",
       " 'remind': 458,\n",
       " 'elbows': 459,\n",
       " 'systemwide': 460,\n",
       " 'return': 461,\n",
       " 'customerservice': 462,\n",
       " 'meetthefleet': 463,\n",
       " 'tlc': 464,\n",
       " 'hometown': 465,\n",
       " 'rising': 466,\n",
       " 'rbn': 467,\n",
       " 'meetings': 468,\n",
       " 'db': 469,\n",
       " 'msh': 470,\n",
       " 'wind': 471,\n",
       " 'stream': 472,\n",
       " 'deciding': 473,\n",
       " 'hassle': 474,\n",
       " 'espn': 475,\n",
       " 'wheresthepilot': 476,\n",
       " 'lpdstock': 477,\n",
       " 'dinner': 478,\n",
       " 'continuous': 479,\n",
       " 'badges': 480,\n",
       " 'inexpensive': 481,\n",
       " 'disastrous': 482,\n",
       " 'customerservicefail': 483,\n",
       " 'resell': 484,\n",
       " 'ex': 485,\n",
       " 'hook': 486,\n",
       " 'husband': 487,\n",
       " 'lloyd': 488,\n",
       " 'neveind': 489,\n",
       " 'jumping': 490,\n",
       " 'hops': 491,\n",
       " 'installed': 492,\n",
       " 'tux': 493,\n",
       " 'plus': 494,\n",
       " 'earning': 495,\n",
       " 'xggcntco': 496,\n",
       " 'attentive': 497,\n",
       " 'questions': 498,\n",
       " 'fare': 499,\n",
       " 'term': 500,\n",
       " 'vineyard': 501,\n",
       " 'garbage': 502,\n",
       " 'flintstone': 503,\n",
       " 'awesome': 504,\n",
       " 'hemisphere': 505,\n",
       " 'male': 506,\n",
       " 'passenger': 507,\n",
       " 'mysteriously': 508,\n",
       " 'dnstitrzwy': 509,\n",
       " 'young': 510,\n",
       " 'onto': 511,\n",
       " 'lovesouthwestair': 512,\n",
       " 'sloppy': 513,\n",
       " 'victim': 514,\n",
       " 'phlairport': 515,\n",
       " 'beach': 516,\n",
       " 'newsbusiness': 517,\n",
       " 'flown': 518,\n",
       " 'beingsuckontarmacsucks': 519,\n",
       " 'bumped': 520,\n",
       " 'moodlighting': 521,\n",
       " 'fucked': 522,\n",
       " 'sucks': 523,\n",
       " 'discrimination': 524,\n",
       " 'executives': 525,\n",
       " 'wikipearl': 526,\n",
       " 'ground': 527,\n",
       " 'seat': 528,\n",
       " 'birthday': 529,\n",
       " 'downhill': 530,\n",
       " 'thtime': 531,\n",
       " 'invitational': 532,\n",
       " 'mama': 533,\n",
       " 'sent': 534,\n",
       " 'feel': 535,\n",
       " 'courteous': 536,\n",
       " 'bumping': 537,\n",
       " 'wouldn': 538,\n",
       " 'quotations': 539,\n",
       " 'merge': 540,\n",
       " 'list': 541,\n",
       " 'pr': 542,\n",
       " 'shin': 543,\n",
       " 'impressed': 544,\n",
       " 'outrageous': 545,\n",
       " 'noneother': 546,\n",
       " 'april': 547,\n",
       " 'nearly': 548,\n",
       " 'girl': 549,\n",
       " 'lovely': 550,\n",
       " 'honored': 551,\n",
       " 'unpredictable': 552,\n",
       " 'dial': 553,\n",
       " 'ohk': 554,\n",
       " 'hi': 555,\n",
       " 'superior': 556,\n",
       " 'sz': 557,\n",
       " 'part': 558,\n",
       " 'large': 559,\n",
       " 'dplq': 560,\n",
       " 'nbaakxh': 561,\n",
       " 'rt': 562,\n",
       " 'refund': 563,\n",
       " 'honolulu': 564,\n",
       " 'child': 565,\n",
       " 'delta': 566,\n",
       " 'silence': 567,\n",
       " 'yeseniahernandez': 568,\n",
       " 'several': 569,\n",
       " 'legally': 570,\n",
       " 'ey': 571,\n",
       " 'destinationdragons': 572,\n",
       " 'laundry': 573,\n",
       " 'medal': 574,\n",
       " 'possible': 575,\n",
       " 'round': 576,\n",
       " 'sheesh': 577,\n",
       " 'sc': 578,\n",
       " 'likely': 579,\n",
       " 'result': 580,\n",
       " 'hasn': 581,\n",
       " 'bosnia': 582,\n",
       " 'embossed': 583,\n",
       " 'operation': 584,\n",
       " 'hiccups': 585,\n",
       " 'thankfully': 586,\n",
       " 'bedofroses': 587,\n",
       " 'eri': 588,\n",
       " 'volume': 589,\n",
       " 'uyhr': 590,\n",
       " 'oq': 591,\n",
       " 'flightr': 592,\n",
       " 'pair': 593,\n",
       " 'kleankanteen': 594,\n",
       " 'nomorevirgin': 595,\n",
       " 'rest': 596,\n",
       " 'flightd': 597,\n",
       " 'rolling': 598,\n",
       " 'safetyfirst': 599,\n",
       " 'limit': 600,\n",
       " 'loyal': 601,\n",
       " 'bestdressed': 602,\n",
       " 'accommodating': 603,\n",
       " 'nyjets': 604,\n",
       " 'reinstated': 605,\n",
       " 'susan': 606,\n",
       " 'calgary': 607,\n",
       " 'isthisyourfirsttry': 608,\n",
       " 'waiver': 609,\n",
       " 'festivities': 610,\n",
       " 'rqbxw': 611,\n",
       " 'in': 612,\n",
       " 'jfk': 613,\n",
       " 'kkwiwi': 614,\n",
       " 'announcements': 615,\n",
       " 'summit': 616,\n",
       " 'impress': 617,\n",
       " 'zabsonre': 618,\n",
       " 'gaga': 619,\n",
       " 'lcqlp': 620,\n",
       " 'socket': 621,\n",
       " 'group': 622,\n",
       " 'lucia': 623,\n",
       " 'easier': 624,\n",
       " 'oversold': 625,\n",
       " 'looking': 626,\n",
       " 'hizouse': 627,\n",
       " 'flysfo': 628,\n",
       " 'dxux': 629,\n",
       " 'allowing': 630,\n",
       " 'sick': 631,\n",
       " 'refuse': 632,\n",
       " 'zfroinpszi': 633,\n",
       " 'uncvsduke': 634,\n",
       " 'yyj': 635,\n",
       " 'explain': 636,\n",
       " 'weds': 637,\n",
       " 'milan': 638,\n",
       " 'bold': 639,\n",
       " 'ruth': 640,\n",
       " 'avis': 641,\n",
       " 'likes': 642,\n",
       " 'snag': 643,\n",
       " 'disrespectfully': 644,\n",
       " 'bostongarden': 645,\n",
       " 'cheeze': 646,\n",
       " 'failagain': 647,\n",
       " 'mi': 648,\n",
       " 'son': 649,\n",
       " 'american': 650,\n",
       " 'resolved': 651,\n",
       " 'swfan': 652,\n",
       " 'waltdisneyworld': 653,\n",
       " 'hap': 654,\n",
       " 'altonbrownlive': 655,\n",
       " 'way': 656,\n",
       " 'props': 657,\n",
       " 'islands': 658,\n",
       " 'natca': 659,\n",
       " 'settled': 660,\n",
       " 'substantial': 661,\n",
       " 'century': 662,\n",
       " 'unpleased': 663,\n",
       " 'entertain': 664,\n",
       " 'admiral': 665,\n",
       " 'goodspeed': 666,\n",
       " 'catch': 667,\n",
       " 'example': 668,\n",
       " 'vpym': 669,\n",
       " 'bro': 670,\n",
       " 'hit': 671,\n",
       " 'messages': 672,\n",
       " 'czamkoff': 673,\n",
       " 'costumer': 674,\n",
       " 'prob': 675,\n",
       " 'goods': 676,\n",
       " 'oversized': 677,\n",
       " 'bush': 678,\n",
       " 'acknowledgment': 679,\n",
       " 'stoked': 680,\n",
       " 'nowhereland': 681,\n",
       " 'tray': 682,\n",
       " 'grandbabies': 683,\n",
       " 'sarcastically': 684,\n",
       " 'kurt': 685,\n",
       " 'sarcasm': 686,\n",
       " 'moms': 687,\n",
       " 'contd': 688,\n",
       " 'unitedsucks': 689,\n",
       " 'why': 690,\n",
       " 'delighted': 691,\n",
       " 'angel': 692,\n",
       " 'brandloveaffair': 693,\n",
       " 'th': 694,\n",
       " 'running': 695,\n",
       " 'timco': 696,\n",
       " 'sxvagbrtli': 697,\n",
       " 'opens': 698,\n",
       " 'jammed': 699,\n",
       " 'lesson': 700,\n",
       " 'normal': 701,\n",
       " 'support': 702,\n",
       " 'brought': 703,\n",
       " 'hop': 704,\n",
       " 'ths': 705,\n",
       " 'yvr': 706,\n",
       " 'melaniespring': 707,\n",
       " 'there': 708,\n",
       " 'relate': 709,\n",
       " 'made': 710,\n",
       " 'pure': 711,\n",
       " 'ak': 712,\n",
       " 'kp': 713,\n",
       " 'prior': 714,\n",
       " 'alert': 715,\n",
       " 'wanna': 716,\n",
       " 'guitars': 717,\n",
       " 'spoke': 718,\n",
       " 'position': 719,\n",
       " 'sellout': 720,\n",
       " 'wyoming': 721,\n",
       " 'virginamerica': 722,\n",
       " 'ccicanine': 723,\n",
       " 'hdndl': 724,\n",
       " 'pigs': 725,\n",
       " 'frm': 726,\n",
       " 'shots': 727,\n",
       " 'including': 728,\n",
       " 'eakpa': 729,\n",
       " 'vegetarian': 730,\n",
       " 'than': 731,\n",
       " 'uk': 732,\n",
       " 'toothpaste': 733,\n",
       " 'disgruntled': 734,\n",
       " 'pressurecooker': 735,\n",
       " 'universalorl': 736,\n",
       " 'happytweet': 737,\n",
       " 'getaway': 738,\n",
       " 'nawww': 739,\n",
       " 'flightnightmare': 740,\n",
       " 'geiger': 741,\n",
       " 'knows': 742,\n",
       " 'incompetent': 743,\n",
       " 'heat': 744,\n",
       " 'orange': 745,\n",
       " 'getmartyhome': 746,\n",
       " 'outage': 747,\n",
       " 'continued': 748,\n",
       " 'mercy': 749,\n",
       " 'alerted': 750,\n",
       " 'karinslee': 751,\n",
       " 'view': 752,\n",
       " 'southwestsmoothie': 753,\n",
       " 'narrower': 754,\n",
       " 'vaca': 755,\n",
       " 'skin': 756,\n",
       " 'chairman': 757,\n",
       " 'rental': 758,\n",
       " 'pesky': 759,\n",
       " 'funny': 760,\n",
       " 'web': 761,\n",
       " 'tier': 762,\n",
       " 'dates': 763,\n",
       " 'nvbj': 764,\n",
       " 'pins': 765,\n",
       " 'rang': 766,\n",
       " 'directtv': 767,\n",
       " 'heathrowairport': 768,\n",
       " 'brain': 769,\n",
       " 'cun': 770,\n",
       " 'deeply': 771,\n",
       " 'pieces': 772,\n",
       " 'sisters': 773,\n",
       " 'confused': 774,\n",
       " 'planes': 775,\n",
       " 'volunteer': 776,\n",
       " 'legroom': 777,\n",
       " 'lasairport': 778,\n",
       " 'tucson': 779,\n",
       " 'rockingthetweets': 780,\n",
       " 'applause': 781,\n",
       " 'complains': 782,\n",
       " 'otherwise': 783,\n",
       " 'tattoo': 784,\n",
       " 'albany': 785,\n",
       " 'designer': 786,\n",
       " 'fastest': 787,\n",
       " 'flightn': 788,\n",
       " 'rdtimethishashappened': 789,\n",
       " 'hostage': 790,\n",
       " 'remains': 791,\n",
       " 'tailfinthursday': 792,\n",
       " 'origin': 793,\n",
       " 'beat': 794,\n",
       " 'flysaa': 795,\n",
       " 'problems': 796,\n",
       " 'club': 797,\n",
       " 'natt': 798,\n",
       " 'tossed': 799,\n",
       " 'teach': 800,\n",
       " 'themed': 801,\n",
       " 'exactly': 802,\n",
       " 'searched': 803,\n",
       " 'happened': 804,\n",
       " 'another': 805,\n",
       " 'greatest': 806,\n",
       " 'coles': 807,\n",
       " 'mentioning': 808,\n",
       " 'cyguq': 809,\n",
       " 'buybacks': 810,\n",
       " 'youre': 811,\n",
       " 'ts': 812,\n",
       " 'restriction': 813,\n",
       " 'gnk': 814,\n",
       " 'married': 815,\n",
       " 'fong': 816,\n",
       " 'adams': 817,\n",
       " 'duh': 818,\n",
       " 'transactional': 819,\n",
       " 'offenders': 820,\n",
       " 'oak': 821,\n",
       " 'we': 822,\n",
       " 'construction': 823,\n",
       " 'levels': 824,\n",
       " 'abc': 825,\n",
       " 'informative': 826,\n",
       " 'miranda': 827,\n",
       " 'chk': 828,\n",
       " 'jokesonus': 829,\n",
       " 'alone': 830,\n",
       " 'blatant': 831,\n",
       " 'ppvq': 832,\n",
       " 'vomit': 833,\n",
       " 'https': 834,\n",
       " 'returned': 835,\n",
       " 'colored': 836,\n",
       " 'zi': 837,\n",
       " 'badbadbad': 838,\n",
       " 'excuses': 839,\n",
       " 'reaching': 840,\n",
       " 'reports': 841,\n",
       " 'nope': 842,\n",
       " 'happyflier': 843,\n",
       " 'main': 844,\n",
       " 'force': 845,\n",
       " '!': 846,\n",
       " 'aypyaduy': 847,\n",
       " 'aboard': 848,\n",
       " 'ella': 849,\n",
       " 'cheesy': 850,\n",
       " 'gracious': 851,\n",
       " 'inexcusable': 852,\n",
       " 'stunned': 853,\n",
       " 'messing': 854,\n",
       " 'feelbetter': 855,\n",
       " 'truck': 856,\n",
       " 'hangar': 857,\n",
       " 'fro': 858,\n",
       " 'fl': 859,\n",
       " 'airlinegave': 860,\n",
       " 'joking': 861,\n",
       " 'individual': 862,\n",
       " 'strategy': 863,\n",
       " 'around': 864,\n",
       " 'woohoo': 865,\n",
       " 'dustyob': 866,\n",
       " 'don': 867,\n",
       " 'cldnt': 868,\n",
       " 'tmm': 869,\n",
       " 'unitedairlinessuck': 870,\n",
       " 'purpose': 871,\n",
       " 'wasappreciated': 872,\n",
       " 'yeehaw': 873,\n",
       " 'sunburn': 874,\n",
       " 'responsibility': 875,\n",
       " 'refueled': 876,\n",
       " 'turning': 877,\n",
       " 'slowly': 878,\n",
       " 'hair': 879,\n",
       " 'airports': 880,\n",
       " 'cuz': 881,\n",
       " 'stillmakingmepoorthough': 882,\n",
       " 'my': 883,\n",
       " 'statement': 884,\n",
       " 'booted': 885,\n",
       " 'preference': 886,\n",
       " 'logo': 887,\n",
       " 'overheating': 888,\n",
       " 'entry': 889,\n",
       " 'delhi': 890,\n",
       " 'between': 891,\n",
       " 'crossed': 892,\n",
       " 'ha': 893,\n",
       " 'appreciated': 894,\n",
       " 'average': 895,\n",
       " 'ilookyoung': 896,\n",
       " 'dbfd': 897,\n",
       " 'wi': 898,\n",
       " 'communications': 899,\n",
       " 'til': 900,\n",
       " 'dress': 901,\n",
       " 'overcharged': 902,\n",
       " 'sjc': 903,\n",
       " 'reconsider': 904,\n",
       " 'hosting': 905,\n",
       " 'isp': 906,\n",
       " 'sat': 907,\n",
       " 'experienced': 908,\n",
       " 'cvg': 909,\n",
       " 'fraction': 910,\n",
       " 'slobodin': 911,\n",
       " 'pls': 912,\n",
       " 'albuquer': 913,\n",
       " 'jackpot': 914,\n",
       " 'mclarren': 915,\n",
       " 'janet': 916,\n",
       " 'yay': 917,\n",
       " 'sfotobos': 918,\n",
       " 'connecting': 919,\n",
       " 'leanin': 920,\n",
       " 'vacay': 921,\n",
       " 'leatherseats': 922,\n",
       " 'suggested': 923,\n",
       " 'cometoaustin': 924,\n",
       " 'credibility': 925,\n",
       " 'solve': 926,\n",
       " 'acts': 927,\n",
       " 'frame': 928,\n",
       " 'bestinclass': 929,\n",
       " 'prom': 930,\n",
       " 'evenmorespace': 931,\n",
       " 'illogical': 932,\n",
       " 'necessary': 933,\n",
       " 'unhappytraveler': 934,\n",
       " 'concentrate': 935,\n",
       " 'wet': 936,\n",
       " 'priceless': 937,\n",
       " 'helping': 938,\n",
       " 'southwestairlines': 939,\n",
       " 'member': 940,\n",
       " 'coming': 941,\n",
       " 'skyteam': 942,\n",
       " 'jnpjm': 943,\n",
       " 'intimate': 944,\n",
       " 'brilliant': 945,\n",
       " 'certainly': 946,\n",
       " 'finally': 947,\n",
       " 'h': 948,\n",
       " 'unusable': 949,\n",
       " 'floors': 950,\n",
       " 'problem': 951,\n",
       " 'anticipate': 952,\n",
       " 'tfw': 953,\n",
       " 'nonstop': 954,\n",
       " 'sw': 955,\n",
       " 'encourage': 956,\n",
       " 'ucvnilmb': 957,\n",
       " 'nto': 958,\n",
       " 'marsha': 959,\n",
       " 'bathroom': 960,\n",
       " 'reading': 961,\n",
       " 'december': 962,\n",
       " 'inconveniently': 963,\n",
       " 'rather': 964,\n",
       " 'burn': 965,\n",
       " 'displeasure': 966,\n",
       " 'lostinlove': 967,\n",
       " 'glitches': 968,\n",
       " 'pv': 969,\n",
       " 'numofpointsavailable': 970,\n",
       " 'vwq': 971,\n",
       " 'revive': 972,\n",
       " 'specific': 973,\n",
       " 'kidnapped': 974,\n",
       " 'sundayfunday': 975,\n",
       " 'english': 976,\n",
       " 'lf': 977,\n",
       " 'held': 978,\n",
       " 'counts': 979,\n",
       " 'perceived': 980,\n",
       " 'surname': 981,\n",
       " 'swapic': 982,\n",
       " 'nghmie': 983,\n",
       " 'challenge': 984,\n",
       " 'santa': 985,\n",
       " 'siting': 986,\n",
       " 'tnx': 987,\n",
       " 'final': 988,\n",
       " 'norris': 989,\n",
       " 'djjjn': 990,\n",
       " 'circumstances': 991,\n",
       " 'make': 992,\n",
       " 'any': 993,\n",
       " 'definitely': 994,\n",
       " 'companions': 995,\n",
       " 'zpu': 996,\n",
       " 'isml': 997,\n",
       " 'it': 998,\n",
       " 'causing': 999,\n",
       " 'outlets': 1000,\n",
       " ...}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_value = data.text.apply(lambda x: [word_index.get(word, 0) for word in x])    #获取每个word的value值，没有索引则填充为0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_value.iloc[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_length = max(len(x) for x in data_value)              \n",
    "max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_value = keras.preprocessing.sequence.pad_sequences(data_value.values, maxlen = max_length)   #填充所有评论至40个单词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4726, 40)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_value.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.review.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 建立模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embedding 把文本映射为密集向量的层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(layers.Embedding(max_word, 50, input_length = max_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(layers.LSTM(64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(layers.Dense(1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 40, 50)            355050    \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 64)                29440     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 384,555\n",
      "Trainable params: 384,555\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['acc']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3780 samples, validate on 946 samples\n",
      "Epoch 1/10\n",
      " 128/3780 [>.............................] - ETA: 23s - loss: 0.6913 - acc: 0.6719"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": " indices[61,35] = 7101 is not in [0, 7101)\n\t [[node sequential/embedding/embedding_lookup (defined at D:\\Users\\Administrator\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py:1751) ]] [Op:__inference_distributed_function_3452]\n\nFunction call stack:\ndistributed_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-41-afcfde7207f8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreview\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Users\\Administrator\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 728\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    729\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    730\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32mD:\\Users\\Administrator\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[0;32m    322\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 324\u001b[1;33m                 total_epochs=epochs)\n\u001b[0m\u001b[0;32m    325\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    326\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\Administrator\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[1;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[0;32m    121\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[0;32m    122\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 123\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    124\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m         \u001b[1;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\Administrator\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[1;34m(input_fn)\u001b[0m\n\u001b[0;32m     84\u001b[0m     \u001b[1;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[1;32m---> 86\u001b[1;33m                               distributed_function(input_fn))\n\u001b[0m\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\Administrator\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_counter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcalled_without_tracing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\Administrator\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    485\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    486\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 487\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    488\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    489\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\Administrator\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1821\u001b[0m     \u001b[1;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1822\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1823\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1824\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1825\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\Administrator\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1139\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[0;32m   1140\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[1;32m-> 1141\u001b[1;33m         self.captured_inputs)\n\u001b[0m\u001b[0;32m   1142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1143\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\Administrator\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1222\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[1;32m-> 1224\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[0;32m   1225\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\Administrator\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 511\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    512\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32mD:\\Users\\Administrator\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m     \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m     keras_symbolic_tensors = [\n",
      "\u001b[1;32mD:\\Users\\Administrator\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m:  indices[61,35] = 7101 is not in [0, 7101)\n\t [[node sequential/embedding/embedding_lookup (defined at D:\\Users\\Administrator\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py:1751) ]] [Op:__inference_distributed_function_3452]\n\nFunction call stack:\ndistributed_function\n"
     ]
    }
   ],
   "source": [
    "model.fit(data_value, data.review.values, epochs=10, batch_size=64, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
